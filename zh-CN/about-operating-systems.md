# 关于操作系统

# 引言

　　本文汇总讨论有关操作系统的观点和相关话题。

# 概念

　　计算机软件是供用户使用硬件的接口。**操作系统**是直接管理计算机硬件资源的软件系统。

　　操作系统作为软件项目可能着眼于不同的粒度。但一般地，至少应包含硬件抽象层(HAL, hardware abstraction layer) 作为隔离硬件细节和其它软件的统一接口。

## 组成

　　不少操作系统提供包含用户界面(UI, user interface) 在内的一整套程序。有的操作系统则仅限于直接管理硬件的程序及其应用程序接口(API, application programming interface) 。一般地，后者的设计决定了操作系统的主要部分，但前者的形式在如何使用上会发生影响，所以在此一并讨论。

　　直接管理硬件的程序具有控制整个硬件系统的特权，而其它程序可能会相对地受到权限访问的限制。在许多操作系统中，前者称为内核(kernel) ，相应的特权程序称为内核程序。内核程序除了内核，可能包括随 HAL 可能包括适配特定硬件的驱动程序(driver) 或其它一些系统服务。后者在一些系统中，统称为执行体(executive) 。

# 主流操作系统的一些设计问题

　　当代主流的分时多任务通用目的操作系统明显地受到 UNIX 系统的影响。其中有几个非常烂的发明被作为特色保留和发扬光大了起来，导致其它系统设计也一损俱损，乃至扭曲用户的习惯。

　　以下只是挑一些影响比较大的不同方面的（但其实很大程度是交织在一起的）设计缺陷。

## 无原则地划分用户群体和对应的接口

　　系统的 API 本应可以和 UI 用同样的形式来描述。但现在大多数系统都不是这样做的。作为通用语言适配不同体系结构的开山鼻祖，UNIX 是始作俑者，难辞其咎。

　　根本上不得不这样做的理由仅仅是因为历史原因：UNIX 的设计者并没有能耐设计出顶用的抽象来支持一种统一的语言（及其运行时）。结果，接口分为了 C 和 shell 语言描述的两部分。所谓[一行 shell 顶一万行 C ](https://i.linuxtoy.org/docs/guide/ch12s02.html)的经典故事，只是粉饰“无法在提供系统 API 的语言中嵌入足够的抽象机制而不得不再另外造个抽象上看似好用的 UI 语言”这个历史性既定失败的应激反应而已。

　　虽然 C 和 shell 这样的“应用程序语言”和“用户界面语言”这种二分法的设计策略减少了作者对语言设计能力上的要求，但也直接导致了两类语言之间的互操作问题。这里说是“两类”而不是 C 和 shell 两种，是因为不少人觉得 C 和 shell 在各自常用的——尽管其界限完全是人为划分而原则上不必要的——领域都不好用，所以不断有人接着新增不同的语言设计，但大多数语言作者都逃不出要么像 C 要么像 shell 而无法通用这个问题。逐渐地，这个历史失败反而变得像业界常规了。

　　对操作系统来讲，语言设计如何失败是另一类问题，但有理由怀疑 UNIX 本身的一些蹩脚的抽象（如 PID ，具体蹩脚在哪下面另说）仅仅就是为了变通这个失败（更确切地，为了两种语言之间的交互方便这种琐碎的理由）而不得不创造出来的。

　　而更长远的影响是这造成了开发者和用户阵营之间的分裂。开发者本应是用户的一部分，共享相当程度的利益而具有一致的共识——事实上早期的用户大多也是开发者，反而并没有对此有多深刻的体会。之后的所谓 FOSS 以及“生态”之类冠冕堂皇的破事……反正这里放不下就不多说了。

　　最后一个问题的观点并不是什么新鲜的主意，[1990 年代就有人讨论过相关的问题](http://tunes.org/papers/WhyNewOS/WhyNewOS.html#htoc37)。

## 软件和硬件的边界的过早优化

　　为什么指令集架构(ISA, instruction-set architecture) 就配当这个被普遍承认的边界？这根本是个体系结构设计历史的问题，并不是操作系统设计的问题。但在历史上这多少和操作系统的设计的习惯有相当大的关系。

　　导致现状的原因偶然的：早期并没有什么人能通过通用语言派生出设计处理器的硬件描述语言(HDL, hardware description language) 这样的领域特定语言(DSL, domain-specific language) ，所以 ISA 这种习惯上对应某种机器特定语言（现在一般表示成汇编）的接口就被作为中间层了。而同样直接生成 ISA 层次本机代码的 C 以及依赖 C 来实现可移植性的 UNIX 无疑严重地加剧了这一点，现在看来几乎可以说是最具有决定性的原因。之后的偶然演化（特别是商业上的成功）也使这种“大势所趋”无可挽回。而现有的流行 HDL（如 Verilog ）参照 C-like 设计也相当程度上说明了这种臭味相投。

　　即便不考虑集成电路设计行业的不得不使用抽象能力具有缺陷语言的倒霉蛋，这里的影响仍然是相当深刻的：

* 如所谓本机调用栈(native call stack) 以及 ring-based security 这些原则上只配作为个别实现的偷懒选择，在硬件层面上获得了支持而具有不公平的竞争优势。加上 ISA 本身的兼容性包袱，其它体系结构设计就变相被非技术理由而淘汰了。
	* 这反过来对多任务操作系统设计又有极其重大的近乎关乎全局的影响。
	* 虽然操作系统原则上只需要提供一个 HAL ，这里的许多东西都可以被绕过（例如 IA-32 上不成器的段式内存管理和任务寄存器(TS, task register) ），但有些东西因为使用 C 这样的语言，想绕过去的成本极其高昂。
		* 首当其冲的是存储管理机制上对内存管理单元(MMU, memory management unit) 这类硬件的依赖。原则上地址翻译虽然被硬件加速了不少，这仍应只是个常数差别的操作，除了 C 这样的本机语言的实现的问题，并不难被模拟。但没有 MMU 的系统上想用 C 模拟出这种操作却不被开发系统的用户普遍接受——他们早就被 MMU 惯坏了。
		* 作为依赖这种实现细节的结果，典型的操作系统在 HAL 之上被迫负担了维护虚拟内存空间的任务。更要命的是，除了地址翻译，这类机制是不方便被专用硬件继续加速的。（反过来，全局垃圾回收(GC, garbage collection) 之类的机制虽然在这些机制为基础再用软件运行时实现的策略下可以说表现极烂，一定程度上却更容易由硬件实现。）依赖硬件加速反而断了后路，可悲可笑。
	* 而硬件上看似实现简单的 ring-based security（题外话，这里的复杂性在很多年后需要虚拟化之类特性的处理器的微架构设计中才暴露出来）又使使用 C 这样的语言的操作系统倾向于直接提供单一的“系统调用”接口来分隔系统本身和所谓用户空间的程序。
* 在几个因素的共同作用下，C 的一些不可预期的实现行为被地址空间隔离这种半吊子容器绥靖了。在这个意义上，诞生了所谓的“进程”（顺便扭曲了“进程代数”之类模型中“进程”的原本含义）这个程序隔离的单位。
	* 依赖进程划分任务边界的直接后果是操作系统在维护内存管理之外，还需要提供进程间通信(IPC) 的接口。
	* 因为 IPC 的性能问题，宿主语言实现往往不方便提供全局列集(mashalling) 的几乎只有系统设计者才能优化好的一等机制（使用 C 这样抽象蹩脚的语言和已经有系统调用这种看似“通用”的方式的既定事实，也给他们足够的借口不提供这类实际上更一般的机制），而直接把 IPC 作为系统调用以上的多任务交互之间的更基本的接口。
	* 这样的接口体系导致了可用性和可扩展性都有疑问的设计——如不得不需要各种在任务之间同步状态的输入/输出 API ，包括所谓的文件描述符之类的抽象……以及使“文件”作为操作系统整体设计的一部分看起来显得更重要（具体下面另说）。

## 一切皆文件(everything is a file)

　　所谓“一切皆文件”，是指用户在接口中看到一个作为操作目标的对象(object) ，就能把它当作“文件”使用。这种设计的直接问题是：什么是所谓的“文件”？

　　从大部分使用来看，“文件”的含义是混乱的，很难从外延上概括清楚。而这种设计在内涵上的合理的部分其实只是“系统资源可以用基于虚拟文件系统(VFS, virtual file system) 提供的多层命名空间的路径作为参数的接口访问”这点而已。

　　注意合理性讲的是“可以”，而不是“必须”。实际的系统也在这里也明显有妥协，特别是涉及具体的特殊文件系统时——比如 `procfs` 这样的文件系统原则上就不可能保证很好的兼容性。

　　除了这个合理性之外，“一切皆文件”和面向对象鼓吹的“一切都是对象”一样几乎都是废话。这不仅无用，还有害，而且实际上也不可能合理贯彻——因为对系统本身来讲，VFS 是外加的抽象，内部访问也用 VFS 就太蠢了——而强迫用户使用只使用 VFS 而不能使用其它（不用路径的）方式是另一种蠢。特别地，对某些系统，既然敢向用户空间暴露（姑且算稳定的）系统调用接口，咋不把系统调用表也整成所谓的“文件”呢？（想想谁来实现这样的“文件”？）

　　另一个缺陷是它没有合理划分系统本身和用户空间之间的职责界限（这和上面说的为什么 ISA 成为了软硬件之间的边界以及系统调用成为系统和用户空间的边界类似地阳春）。用户空间被设计成不得不依赖这样的机制，而系统自身也为了偷懒而使用——到底什么地方必须要用，就稀里糊涂了。作为一个结果，一些逻辑上类似的接口不得不在系统内部和用户空间提供至少两个版本的实现。

　　考虑一个问题，为什么会要有 [FUSE](https://zh.wikipedia.org/wiki/FUSE) 这样的接口？因为 VFS 在用户空间足够“好用”，而之前的 VFS 的实现不得不依赖系统自身的一些模块来实现，但这种设计因为性能和侵入系统实现影响稳定性之类的原因并不总是对用户空间的需求好用……都知道这样，为什么不在一开始就分别设计呢？——因为这样就没法复用现有系统接口的语义了。为啥要复用？因为历史包袱，不复用的话很多东西要重新实现，还不怎么方便抄……但其实能复用也就是复用一部分，一样有大把逻辑要重新实现。

　　所谓“一切都是对象”的“对象”如果理解成一等对象(first-class object) 那么姑且点用，可惜 UNIX 传统上的 C 也好 shell 也好都根本发挥不出这个抽象的能力（早期也没能力实现）于是干脆也就不提供了（比如说，“函数”就不能直接当参数来传，这蕴含着语言根本就没法提供机制来代替显式用户编码的、经常依赖二进制实现细节而削弱可移植性的闭包，而偏偏用户很多时候不得不这么做）。
而对语言中的接口来讲，允许保持资源对象的匿名性是资源作为（各种不同定义下的）一等对象的前提。强制资源放到 VFS 上具名引用反而削弱了这个特性；不过这又是另一回事了。

　　文件操作的可用性可能依赖具体文件系统的实现，然而 VFS 不能为此提供充足的保证，这使某些通过 API 暴露的 VFS 操作在不清楚实现细节的情况下变得无用。例如 [至少 Linux 的 `readdir` 结果中的可靠的 `d_type` 需要特定的文件系统支持](http://man7.org/linux/man-pages/man3/readdir.3.html) 。（讽刺的是，就这个例子而言，因为缺乏实现和系统自身的支持，Win32 上这样的扩展一般通过 如 [mingw.org](mingw-vs-mingw-v64.md) 用户空间的单独实现提供，虽然可移植性打折扣，却不会发生 API 看上去能用而实际无法使用的情况。）

　　文件的持久化特性被作为 IPC 的替代（其实该是备胎）则是这个基础上的偶然。因为没有像样的一等对象来直接映射到持久对象上，用户程序中的对象都是被限制在进程生存期之内的，缺乏普遍的持久化机制（这又可以成为系统不提供列集机制的一个借口了）。文件必须被“打开”成为所谓的流(stream) 才能成为进程中被继续操作的资源。除了复杂性，这里的“流”的概念还挤掉了原本正常的类似 SRFI-45 的数据结构，让用户更加稀里糊涂。

### Windows NT

　　Windows NT 内部的设计在这里大同小异，但有一些更烂的旮旯。这些烂的问题是如此杂乱和普遍而且暴露给了上层，结果对普通用户来讲，体验糟糕到相比之下 POSIX 的 VFS 抽象本身的更原则性的缺陷似乎都算不上什么了。

　　其实在原则上 NT object system 基本上遵循了 VFS 中最顶用的一些设计，但它没把这层抽象暴露给用户空间，而仍然让传统（又是兼容性包袱）接口——从 CP/M 到 MS-DOS （一开始还不支持多层结构）到 Win32 的烂设计——来冒名顶替涉及标识 VFS 命名空间中的资源的 UI 甚至 API 。

　　Win32 流行的结果之一用户使用文件系统路径的习惯被盘符之类的垃圾接口设计沾染了。虽然之后的 UNC 一定程度上挽回了这个问题，但多一种约定基本上无济于事，只会使状况更糟糕（况且不少用户还根本不会用）。这是也是为什么在 UI 上 Windows 的命令行接口(CLI, command line interface) 普遍比 POSIX 系统烂的重要原因之一——因为在命令行 shell 的意义上就根本就不存在一个一致的通用约定。还有一个说大不大说小不小的问题是用反斜杠而不是斜杠来作为 VFS 分隔符（虽然这主要恶心的是 C-like 语言 API 的用户）——想想 `"\\\\"` 就令人无语。

　　同样的问题还发生在 NT 和 Win32 这些子系统之间。NT 对象系统用命名空间(namespace) 这个机制来区分不同的 VFS 路径。问题是这种区分是一次性的，通过硬编码的前缀来表示，而不是传统 VFS 继承性。结果到文件系统上，同一个路径可能有多种奇葩的写法（什么 \\?\ ……）。而这些区别并没有彻底限制在 NT 执行体内部而是暴露到用户空间中了，所以有更大的机会引起混乱。（事实上，不久之前我还就见到有人反映 `cmake -E tar` 报错创建 `\\?\` 什么玩意儿的路径的文件失败的……不明白这层关节的用户立刻表示这什么鬼，但是明白这个的也不能保证 `cmake` 出什么鬼问题就是了。）

　　更奇葩的是，Windows 在同一套 API 层面的对不同路径的长度的限制还不同（其实还有 A/W 问题，不过这个跟 NT 和 Win32 本身没多大关系，略），不过这又是 Windows 如何罄竹难书的另一回事了。

　　（但话说回来，习惯在用户空间 API 硬点逻辑上莫名其妙的缓冲区长度限制本身这就是 UNIX 时代种下的恶果——因为 C API 根本就没本事维护清楚什么系统资源的限制是合理的。扯远点，甚至到今天 C 以及 C++ 都不能保证嵌套函数调用一定有可预测的行为。这是一脉相承的问题，显然不是操作系统本身设计能解决的。）

### URL

　　使用 URL 统一作为路径的规范格式无疑算是比现有一般 VFS 更有吸引力的解决问题的设计技巧。在大多数系统中，VFS 没有直接使用 URL ，shell 也不直接提供统一的支持，导致并 URL 在 VFS 中实际不通用。[某些系统的 VFS 设计试图改变这个现状](https://doc.redox-os.org/book/introduction/why_redox.html)以获得更好的接口一致性。不过，这并没有解决 VFS 中应该对“文件”提供什么样的公共操作的这个更麻烦的本质问题。

　　此外，在 API 上，若仅仅把作为 URL 作为传统 VFS 路径字符串的替代品，也不保证继续保留一些次要的但关键的缺陷，如无原则的路径长度限制。

## 面向文本(text oriented)

　　这里的问题又有两个层次：先是搞乱“文本”和非文本的界限，再是漠视处理结构化数据的需求。总的效果是提供了虚假的保证而造成使用上的问题。

　　因为历史上的混乱，其实大多数人都不容易能搞清楚现在的计算机中处理的所谓“文本”是什么。作为常识，文本首先是人类的书写系统的抽象；对许多书面语言，包括原始的 UNIX 系统一开始支持的英文，这可以表示以字符(character) 为字典集合的元素的串(string) 这种序列。但因为包括 UNIX 在内的歪曲性的推广，这个正常的含义实际上不太可靠。

　　对 UNIX 之类的系统来说，文本实际上是指那些从不分辨编码的流的源（所谓“二进制文件”，或者更确切地说，octet ）中，被特别处理方便用户接口处理，视觉上能辨认的那部分文件。（一个副作用：所谓“二进制文件”被一些人专指“不是文本文件的二进制文件”，或者说“内容以在视觉上看起来不是文本的文件”，这个说法非常流行而导致了另一层面上的混乱。）

　　不幸地是，因为保存 UNIX 系统中的文本的外部表示通常随意依赖 C 对串这类数据的内部表示进行处理的传统，这里界定数据是否算是文本的标准其实是相当随意的。C 所谓的字符作为串的元素，经常被初学者误认为是文本的要素，但实际上就是一类整数罢了；所谓字符串(character string) 也就是恰好能作为表示所谓文本的东西，实际上并不存在保证被表示的数据是文本的限制。C 对所谓字符集(character set) 的假设也相当地粗浅，也并没在编码(encoding) 的意义上提供什么跟日常中的“文本”相近的保证。极端地如，被编码为 NUL （整数 0 ）的所谓空字符(null character) 并不是能表示文本的数据，尽管 C 约定字符串不应该具有这个“字符”，字符串字面量(string literl) 却允许其中夹杂 `\0` 。而其它一些语言中还直接允许在惯用于表示字符串的类型的值中夹杂空字符（如 C++ 允许 `std::string` 中夹带 `char(0)` ）。这些细节无疑在 API 上削弱了用串表示文本的可靠性，使用这些语言的应用程序开发者因为互操作性兼容问题也不敢随意修改这些惯例而传递到 UI 的设计上（例如 POSIX 工具中提供的一些 `-0` 的惯例特别处理——虽然细心的用户在这里不应该被混淆），久而久之“文本”的概念就自下而上地扭曲了。

　　公平地说，这并不完全是操作系统设计自身导致的，而是一个普遍的历史包袱。如 ASCII 这样的编码，一开始就不是作为什么分层的方案来设计的，这导致了抽象上的混乱：原本不一定适合用于表示纯粹书写系统的编码，被一些用户误认为文本，而另一些用户不是。用现在的话概括地说，适合作为传输层以下的控制码和应用层被表示的内容在编码方案上被混在了一起。作为具体的例子，像“新行”(LF, line feed) 这样引起逻辑和视觉上都可重现的文本变化作用的所谓控制字符(control character) 姑且能作为可打印字符(printable character) 这样明确算是传统意义上的文本数据的扩充的话，凭什么“响铃”这样的动作也能编码成所谓的控制“字符”呢？这其实是在滥用文本中的“字符”的抽象。而真正在此需要的仅仅是传输层以下的应用中需要被编码的代码点(code point) 。这在历史上造成了一些实际的问题，如需要支持[ANSI 转义序列](https://zh.wikipedia.org/zh-cn/ANSI%E8%BD%AC%E4%B9%89%E5%BA%8F%E5%88%97)。这类抽象不当的问题在后来的 Unicode 的设计中被通过严格地区分（此外还有字形(glyph) 的概念）来避免，但 Unicode 并没解决什么东西都往“字符集”里塞的问题；以合法的 Unicode 代码点表示的数据，被纯粹作为表示日常意义上的“文本”的“字符”来对待，仍然不保证是靠谱的。而像[彩色 emoji](http://unicode.org/reports/tr51/) 之类的 Unicode 新特性也导致 Unicode 编码的内容离纯粹的文本渐行渐远了。

　　更根本地，把这些编码混用作为应用的外部表示，犯了违反关注点分离原则的错误：实质上混淆了真正的输出和控制输出的输入行为。这两种信息并不都直接表示文本，因此在所谓的文本流中并不应该被同等地编码：前者是表示文本的传统意义上的字符，要求编码上的稳定性；后者实际上不需要这样的性质。允许编码控制输出行为所谓控制字符只是避免冗余编码转换实现权宜的变通，在编码转换开销已经被通信网络设备平摊的当代已经基本没有什么意义；夹杂这类所谓的字符反而使文本流在视觉上不得不被排除出文本，还浪费编码空间中有限的代码点。而在现代的图形用户界面(GUI, graphical user interface) 程序中，即时响应的用户的交互式输入都普遍地不占用外部编码，也体现了这个原则。

　　但是，像 UNIX 极大地依赖这种文本似是而非的约定的用户界面习惯使这种错误长期无法得到纠正，是既定事实。例如：

* 在 ISO C 的标准输入/输出接口中，保留了所谓的文本模式(text mode) ，实际作用仅仅是区分行尾(EOL, end-of-line) 。这并不是强制被区分的。对 POSIX 系统，文本模式和非文本模式（所谓的二进制）是一样的，都只有一个 LF 。
	* 这在逻辑上造成了一些混乱：作为和外部系统共通的持久化编码的文本流，它的文本输出表示理应是兼容的。凭什么 POSIX 系统上的 EOL 就是换行，而 Windows 上就必须是回车符(CR, carriage return)+LF ？虽然 ISO C 在作为流的外部表示的“文件”上并没有多少保证，考虑到文本文件广泛使用类似的编码标准，这仍然在相当程度上直接削弱了 C 的实现的可移植性。
	* 特别地，大多数通用的 Internet 文本协议，如 HTTP 、SMTP 、FTP 和 IRC，都明确要求 CR+LF 作为 EOL 。这种情况下，默认使用 LF 的“文本”系统反而并不“文本”了。
* 有的用户认为文本文件不应该具有字节序标记(BOM, byte-order mark) 。这是对传统文本表示的误读。这种误读在 UNIX 用户的惯例中尤其常见。
	* 事实上，在文本文件中的 BOM 本质上是引导和文件内容的文件头(file header) ，标识文件的格式——对文本文件，BOM 指定是遵循的编码（可能包含字节序）。这在二进制文件中是惯例，然而为什么有的用户对此持有双重标准？
	* 假定文本的格式可能合适个别程序内的内部使用，也适合明确依赖文本内容假定的应用程序（如 POSIX 的 `cat` ）；但作为文本流的外部表示，这并不合适。
		* 排除 BOM 这样的文件头并不保证“文本文件”具有的内容被作为合法(valid) 的文本流。如在 POSIX 这种要求字节具有 8 位的表示中环境中，ASCII 这样的 7 位编码以二进制字节流表示，总是有可能具有冗余的（高位为 1 的）不合法的代码点。而要是总是把文件看作字节流，那么就不可能在不校验内容的前提下，从外部文件之类的不可靠来源提供的文本流是合法的。用户只能假定其内容合法。
		* 任何缺乏 BOM 等标记的纯粹由文本流的内容（以字节流填充二进制文件等形式）构成的文件，要确认其中内容的合法性都需要另外的假定。这引起实际应用中对文本文件编码的猜测。而[假定任何文本文件的不明编码默认都是 UTF-8 并不能解决所有问题](criticisms-on-UTF-8-everywhere-manifesto.md)，仅仅是一种变通。
	* 这种标记文本格式的文件头类似编程语言的名义类型系统，具有特定名义标记的“强类型”保证所谓的类型安全——表示已经在之后跟随的内容中排除了不合法的表示。没有文件头的纯粹的文本流构成的文件，相当于“不安全”数据：用户假定文件内容在格式上是可靠的。为什么某些用户要在积极利用“强类型”的语言和利用文本文件头的问题上持双重标准？
	* 关于双重标准，可能仅仅是滥用习惯，并没有其它原因。模糊不清的文本概念的约定这也影响到其它一些方面的用户习惯，并进而导致更扭曲的接口设计（例如，欠缺普遍的配置格式约定）。
* 文本似乎给了用户一种数据内容较更规则的错觉，仅仅是因为它们在特定的应用程序中看上去更可读。

　　对文本和文本文件格式的理解已经显示出对某些用户对被处理的数据中应该具有的结构的理解的偏差。这种认知问题的更进一步迹象是否定数据内容的结构要求，坚持在系统中和 UI 交互的程序默认总是以平坦的“字符”序列组成的所谓文本来处理数据，而不顾实际需求。这不但进一步无意义地割裂了 许多已有的 API 和 UI 的设计风格而使未来的用户更加容易无所适从，还造成了许多用户习惯和认知的冲突，乃至反映在用户社区政治上：例如，某些用户对 `systemd` 的抵制的一个主要理由是“不使用文本”，全然不顾类似的任务需求是否应该依赖于使用文本。（当然，以其它的理由抵制 `systemd` 是另一回事。）

## 管理资源的接口

　　除了 VFS ，POSIX 系统还提供其它传统上 UNIX 的资源抽象方式：用一个整数作为标识——某些机制也同时被用于其它系统。两个典型的例子有资源标识符和描述符。同样是整数，这两者却代表了两种不同的设计失败的典型。

　　进程标识符(PID, process ID) 是资源标识符的一个典型的例子，它试图抽象一个运行时的用户空间进程。之所以说是试图，是因为它并不可靠——它可能根本不对应一个在生存期内的进程，或者干脆对应一个已经结束的僵尸进程(zombie process) 。造成这些问题的首要根本原因是作为标识符的整数自身的集合并不能和真实的资源集合对应，需要有分配的机制，而分配本身可能有并发访问的冲突而不可靠。另一方面，为了在系统中解决同步问题，系统不能保证直接释放进程占用的资源，而必须在特定的关键资源释放后才能完成进程占用的清理（对 POSIX ，这种资源是进程退出状态；对 Windows ，这种资源是进程句柄(process handler) ），若用户空间程序没有正确地引用这些关键资源，则系统无法释放进程占用的资源而造成资源泄漏，进一步导致 PID 无法被复用。这种并不易用，在出错时也可能十分难以发现原因的设计，除在一定程度上照顾到 shell 语言的互操作性外，完全是鸡肋。而像 UID(user ID) 之类的实体标识符，也可能存在分配问题。此外，由于这些整数标识符是相对某个系统安装实例而言的，在网络上不足以标识实体实现安全审计上的目的；相对地，Windows NT 使用的 SID(security ID) 则没有那么大的问题，只是对 UI 操作不友好罢了。

　　描述符通常标识进程之内使用的资源。一个典型的例子是表示打开文件的文件描述符(FD, file descriptor) 。除了之前提及的文件和流的概念的混淆问题，它比系统中的标识符通常更没用：因为每个进程都可以有一组无关的描述符，所以 IPC 不能直接可靠地使用这些抽象。而对进程自身的可编程接口，类似句柄(handler) 这样的不透明指针更有用。常见对 FD 的使用大多局限于预先约定的知名(well-known) FD ：用 `0` 、`1` 和 `2` 分别代表进程默认打开的输入流、输出流和错误流而已，除了输入起来偷懒省事这个原因，这完全可以用更有可读性的 UI 代替，比如 ISO C 的 `stdin`、`stdout` 和 `stderr` ；甚至若不是在系统设计中总是要求关联这些流，这些“文件”在概念上也是冗余的。

　　以整数标识资源的共同缺陷不但琐碎，还有共同的冗余：既然说“一切皆文件”，为什么不干脆直接用 VFS 标识？有一些系统还真这样做了（如 Linux 支持 procfs ），但加上兼容和 API 设计的限制的包袱，旧的整数标识机制也不能说扔就扔，而新的机制又没那么良好的可移植性。结果就变成两套机制共存的局面。这种为了去除不一致而结果上增加冗余的状况，有些令人哭笑不得。

## 不恰当的设备抽象

　　操作系统抽象硬件，把硬件的机能以软件接口的方式提供给用户使用。但这实际上并非仅有的套路。不少系统提供了更一般的设备驱动框架，允许用户虚拟并不存在的硬件设备进行工作。这是一个灵活的特性，但当遇到一些古董时就哑火了。

　　最显著的例子是控制台(console) 和终端(terminal) 。历史上，这些设备曾经作为用户交互的视频及文本的终结点而起到重要的作用。时至今日，PC 或者其它移动设备下，物理控制台和终端已经过时。但作为历史包袱，不少操作系统仍然保持了这样的设备抽象，而不是给用户在默认情况下摆脱这些开销的选择。

　　大多数的现代操作系统的用户使用这些设备抽象的唯一目的是合理地利用 shell 进行 CLI 程序的交互，他们仅接触虚拟设备——通过现代的键盘和监视器等通用的输入/输出设备上模拟的控制台终端或通常称为终端模拟器的 GUI 程序，事实上并不需要在乎他们使用的是不是像是控制台和终端的设备，自然用不到这套设备抽象。相反，维持设备抽象的历史习惯还限制了键盘的默认绑定：只要不是只使用终端的用户，至少需要记忆终端和非终端下两套不同的键盘设置才能同时使用 CLI 程序和 GUI 程序交互——这是很不友好的体验。而这里默认放弃前者从交互能力（而不是历史习惯）上应该是很清晰的选项。

　　匪夷所思的是，某些系统道德用户仍然以体统多支持了这些（用不到却甩不掉的）特性为荣。甚至当因为缺少这些支持的而出现不兼容的情况时，某些开发者首先倾向于支持历史包袱。[Windows 10 1903 添加 ConPTY](https://devblogs.microsoft.com/commandline/windows-command-line-introducing-the-windows-pseudo-console-conpty/) 是最近一些年来的一个典型的例子。这很容易制造出更复杂的系统机制及割裂用户群体（如 [Windows Terminal 依赖这项新特性](https://github.com/Microsoft/Terminal#installing-and-running-windows-terminal)，而至少我能总是重现一些 Windows 10 1809 及之后内核问题而无法部署这些版本），原本的包袱因为兼容问题又无法彻底抛弃。很难预料到这样的改变会改善多少现状：

* 添加不依赖原有的 ConDrv 的旁路就应该是原生支持的更靠谱的默认设计——**操作系统默认就不应依赖像 ConDrv 这样的内核模式驱动程序来模拟非物理设备的终端**。但是，**这并不是这种设计需要支持完整的 PTY 特性或尽可能模拟终端特性的理由**。
	* 这里的关键是，CLI 程序需要直接和控制台主机 `conhost.exe` 双向通信，而不是经过 ConDrv 这样的间接层；添加新的设计多少有利于甩掉 ConDrv 这个历史包袱；但使这样的行为更接近 PTY（而不是原有的控制台 API ）是没有兼容 UNIX 习惯的历史包袱以外的意义的。
	* 依赖终端特性的一个优势是支持终端功能的丰富。然而就非物理终端支持的功能来讲，再丰富能有 GUI 的终端模拟器的允许实现的效果丰富？
	* 使用终端特性的另一个优点是存在标准化，如 [X/Open Curses](https://pubs.opengroup.org/onlinepubs/7908799/xcurses/curses.h.html) ——不过这在 Windows 中没有特别需要被支持的意义。
	* 另一方面，CLI 程序中即便依赖终端特性实现的部分也不一定直接去和终端通信，而可能调用 [ncurses](https://zh.wikipedia.org/zh-cn/Ncurses) 之类的间接层 API 。然而，支持这类 CLI 程序和有需要用 PTY 支持来实现有什么关系？像 [PDCurses](https://pdcurses.org/) 这样的实现在 Windows 上根本就不依赖 PTY ……
	* 这类兼容 curses 的库，其 API 设计上并不干净，至少显然地比 Windows 之前的控制台 API 糟烂，虽然有些缺陷和 Win32 API 多少是共通的（比如大量的宏污染）。不直接调用 curses 中间层而直接依赖 [termcap](https://pubs.opengroup.org/onlinepubs/7908799/xcurses/term.h.html) 或者 [terminfo](https://pubs.opengroup.org/onlinepubs/7908799/xsh/termios.h.html) 的 CLI 程序，虽然依赖的库本身污染较少，但也很难干净在代码中到哪里去，甚至整体可能更糟糕。
* 而且，这种改动有一些不可忽视的工程代价。
	* 像 `conhost.exe` 这种一更新就得改动整个系统版本的组件，和外置的用户程序来作为终端模拟器添加 UI 相比修改起来代价显然不小，所以一般应避免在 `conhost.exe` 里加入必要以外的功能而给未来的可维护性添堵。
	* ConDrv 理想情况下应只需要处理已知具有物理终端而不是终端模拟器被连接的场合。原则上，系统知道被启动的应用程序的子系统以及是否存在可被连接的物理终端设备，所以应不难实现，但这需要修改控制台主机以外的 Windows 组件的逻辑，可能不是 the Console team 能决定更改的设计。
* 比起“现代”的一些终端模拟器，Windows 的旧的控制台体验的确足以称得上糟糕，但这几乎全是因为模拟软件（比如 Windows 之前版本中的控制台主机）在 UI 上的功能不足的问题，而非面向客户端通信的 API 不足导致的。
	* 某种意义上，依赖设备抽象机制的软件模拟特性对原则上不需要依赖具体物理或者远程终端设备的目的就是不够合理的，**由此造成兼容性问题不是替换终端的软件的问题，而是在此之上过于依赖终端抽象的 CLI 应用程序的问题**——这种应用程序理应被虚拟环境隔离而不是继续污染 UI 和底层的系统，就像 16 位 MS-DOS 程序显然更适合在 [DOSBox](https://www.dosbox.com/) 而不是在 Windows 下继续直接被支持运行一样。
	* 如 [ConEmu](https://conemu.github.io/) 之类的可以仅依赖旧的控制台 API 的终端模拟器足以胜任几乎所有的合理任务。这类终端模拟器也已经为了不合理的使用方式提供了许多兼容性变通，以使之更能称得上算是称职的终端模拟器。某些时候，甚至因为支持过多的模拟特性会出现一些兼容性问题（比如终端模拟器对 ANSI 转义序列的支持可能和假定终端不支持而自行处理的 CLI 程序冲突）。
* 虽然添加 ConPTY 有其合理性，添加类似 *NIX 的 PTY 的 ConPTY 支持的官方理由却相当地故弄玄虚：
	* **Windows lacks a PTY infrastructure** 这只是为了支持 PTY 而支持 PTY 的同义反复。ConPTY 需要有类似 PTY 直接与作为客户端的命令行程序双向通信的功能，并非需要直接需要支持 VT/Text 形式的输入和输出。实际上，也并非需要提供连接标准输入和标准输出流的 API 实现原先的目的，只是这样做比较简明省事罢了。
	* **Windows obstructs 3rd party Consoles and Server Apps** 这只能说明 API 不够充分，是需要 ConPTY 的理由，但不是要求兼容如同 *NIX 特性的 PTY 的显然理由。
	* **Only Windows has a Console API** 这个理由显然地可笑。提供的具有终端特性的抽象仍需 API 支持以被程序使用。事实上，ConPTY 就是以 Win32 API 的形式提供的。如果不考虑模拟终端特性，这在一定程度上也是一种控制台 API ——只不过是扩充了原有的 API 而已。如果可以实现前述的 ConDrv 只处理物理终端设备的特性，同样可以实现修改旧的控制台 API 使之和 ConPTY 一样不经过 ConDrv 。
	* **Windows Command-Line Remoting is substandard** 同上，这仍然是需要 ConPTY 而不是 PTY 的理由。

　　除了习惯向历史包袱妥协的原因，这种盲目堆砌过时特性的习气可能还有某些设计者和用户都不清楚[约定优于配置](https://zh.wikipedia.org/zh-cn/%E7%BA%A6%E5%AE%9A%E4%BC%98%E4%BA%8E%E9%85%8D%E7%BD%AE)的软件设计范式的缘故——过时的无法自适应的配置再丰富，也没有默认可用的配置顶用。

## 安全机制的普遍缺陷

　　尽管被操作系统支持的一开始就被作为（至少系统实例范围内的）共享资源，文件和文件系统设计之初并不考虑安全性。这包括两个方面：持久化的和运行时访问的问题。

### 持久安全机制

　　持久安全机制是和文件相关的元数据维护系统安全属性的机制。常见的设计通称[文件系统权限](https://zh.wikipedia.org/zh-cn/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%9D%83%E9%99%90)。

　　类 UNIX 系统在 VFS 上使用权限位的设计在此提供变通。配合用户权限检查，这可以作为一种 DAC（Discretionary Access Control ，[自主访问控制](https://zh.wikipedia.org/zh-cn/%E8%87%AA%E4%B8%BB%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6)） 的访问权限控制方式的实现基础，但本质上不是安全机制，而仅仅是一种授信数据的来源。基于文件所有者而不是角色(role) 或权能(capability) 作为主体的检查机制设计使系统管理员难以细粒度地分配合理的权限；更麻烦的是，脱离初始配置之后的系统运行时可能修改权限，而修改是否被预期，结果是否真实可靠，原则上是没法通过审计跟踪的。这种简单粗暴的设计和检查机制的实现使用户倾向摆脱正确维护权限的责任而使问题更糟糕。这样的问题又被操作简单却容易误操作的 UI 放大了——随便 `chmod -R` 的后果可能是灾难性的，因为它容易造成难以及时发现的系统故障，且难以通过备份以外的方式恢复。而可执行权限和 shell 的耦合也容易使用户莫名其妙。这类易用性问题使系统管理员和其他用户可能时常需要和不经意的错误配置斗争而无法自动解决，不但无法帮助维护安全性，也无法发挥这种文件系统权限设计的高效性这种相对其它设计（几乎是唯一）的好处，属实鸡肋。

　　Windows NT 则在内核对象管理的层次上使用 ACL（Access Control List ，[访问控制表](https://zh.wikipedia.org/zh-cn/%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6%E8%A1%A8)）储存元数据以跟踪安全事件。使元数据附加到系统中的更一般的实体是相对更合理的方式，因为这个概念不止和实际实现的“文件”相关（例如关系数据库对象也使用 ACL ）。作为 MAC（Mandotory Access Control ，[强制访问控制](https://zh.wikipedia.org/zh-cn/%E5%BC%BA%E5%88%B6%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6)）机制，这也允许系统具有 DAC 的无法实现的功能如 MIC（Mandotory Integrity Control ，[强制完整性控制](https://zh.wikipedia.org/zh-cn/%E5%BC%BA%E5%88%B6%E5%AE%8C%E6%95%B4%E6%80%A7%E6%8E%A7%E5%88%B6)）。Windows NT 的 ACL 实现在易用问题上比 UNIX 权限位更严重（例如长期以来系统不提供可靠的维护 ACL 的可自动化 UI ），使用户更容易忽略其中的潜在问题，不过，这和依赖文件概念进行抽象设计的习惯没有直接的关联。

　　一些 POSIX 系统也引入其它实现补充 MAC ，如 [SELinux](https://zh.wikipedia.org/zh-cn/%E5%AE%89%E5%85%A8%E5%A2%9E%E5%BC%BA%E5%BC%8FLinux) 。不过这没有替代传统 UNIX 文件权限机制，而无法解决后者的固有问题，反而引入附加的复杂性和对应的可用性问题。

### 运行时安全

　　因为历史设计的缺陷，几乎所有的文件系统实现都存在 [TOCTTOU(en-US) 问题](https://en.wikipedia.org/wiki/Time-of-check_to_time-of-use) 。这通过 API 的设计缺陷而广泛存在于（包括系统组件在内的）应用程序的实现内部，因此使用大多数访问文件的应用程序都可能承担系统安全漏洞和应用程序故障的风险。

　　要避免这些缺陷，主流的 POSIX 系统需要修改内核和文件系统的实现，但这仍然不能克服应用程序内部的误用。值得一提的是，NTFS 支持 TxF 原则上可以避免这些缺陷，但[微软废弃和不建议使用这项特性而改以根本无法可靠纠正缺陷的（还对用户引起了其它麻烦的）Windows Installer 和其它兼容性不佳的特性代替](https://docs.microsoft.com/zh-cn/windows/win32/fileio/deprecation-of-txf)，这显然是一种倒退和具有反智倾向的误导。

## API

　　文件和文件系统具有整体上糟糕的 API 。主流的设计和实现长期以来存在如以上的 TOCTTOU 这样的不整体重新设计几乎就没法修复的问题外，还存在其它的一些抽象混乱的问题。

### 可空资源实例

　　文件系统 API 倾向使用不透明指针(opaque pointer) 作为标记文件运行时映像数据结构。这包括 POSIX 的文件描述符(file descriptor) 和 Win32 的文件句柄(file handle)。考虑系统隔离内部资源和用户程序资源的需求，使用不透明指针的设计本身没有问题，但这样的设计有一些其它共通的缺陷：

* 具体语言中使用的静态类型的合理受制于语言特性。
	* 显然文件描述符这样使用 `int` 而导致缺失类型安全检查是个糟糕的选项。
	* Win32 的 `HANDLE` 并没有这样的问题，并且原则上不受制于文件系统对象，不过也无法完全保持二进制兼容性（二进制表示）不变的情形下扩展——因为它预设了特定的值（如 `INVALID_HANDLE_VALUE` ）作为接口约束。
* 这些设计中往往蕴含一个“无效”状态。这造成了高层设计的一些混乱。特别地，蕴含无效值作为合法的值，加重了使用者在错误检查上的负担。
	* 和异常不同，这样的错误容易被忽略而造成程序缺陷。
	* 这样的设计实例有文件描述符的 `-1` 值，和转换为 `HANDLE` 的 `NULL` 值。因为 Win16 兼容性等历史遗留问题，后者实际上更加糟糕，还有 `INVALID_HANDLE_VALUE` 这样的上下文相关的其它无效值。
	* 这使封装系统 API 变成了两难问题：基于这些 API 的更抽象的接口可空的指针直接对应类型的、使用时简单但易错的资源对象，还是多提供一个为了避免误用的不可空的封装？（注意只提供不可空的资源封装不可能利用使用无效值的系统 API ，不是完全可以覆盖用例的设计。）

### 文件和流

　　文件作为数据来源的抽象也已经流毒于操作系统的独立实现之外——至少 ISO C 的流(stream) 在抽象上实质依赖这个概念。这加剧了一些原本就有设计问题的 API 使用的抽象缺陷。

　　虽然 ISO C 意义上的流并没直接要求文件来源，但实现和用户使用时几乎不得不总是考虑它以明确文本模式(text mode) 、多字符字符编码状态(mbstate) 和宽字符指向(wide orientation) 这样的概念。但是，和先前提过的“面向文本”的文本文件的问题类似，这些抽象都有显著使用缺陷：

* 文本模式不可移植。所谓文本模式是指按文本打开流，实际并不验证流的内容格式，而只翻译 EOL（行尾，end-of-line）的[换行](https://zh.wikipedia.org/zh-cn/%E6%8F%9B%E8%A1%8C)字符序列。而 POSIX 只支持 LF 作为 EOL ，Windows 则支持 CR+LF 。并没有统一的方式保证为为一个系统编写的使用文本模式的程序在另一个系统能以相同的方式翻译 EOL 。考虑到文本流的内容通常来自文本文件，而后者可能被遵循不同系统惯例的程序交替地持久使用，忽视这个问题会导致不兼容的文件数据破坏。唯一现实可移植地方式是，总是使用非文本（“二进制”）模式（这和 POSIX 使用 LF 的文本模式兼容），即便是要求 CR+LF 保存换行的文本文件格式（此时显式地加入 CR 来保证数据符合外部约定的格式规范）。
* 文件编码不可移植。虽然流的内容的编码和文本文件这个主要来源类似，是外部可以有明确约定的规范，ISO C 的 API 并没有约定具体的文本编码。所谓的“多字节编码”可能是不兼容的编码，仅考虑东亚文字就有许多不兼容的混乱问题（如 UTF-8、 GBK、 Big5 和 Shift-JIS 混用）。这和文本模式一样可能导致数据损坏。变通方式是，除非必要，总是要求多字节编码的外部表示使用无损表示的编码，如 UTF-8 。不过，这使 ISO C 的相关 API 的可移植性形同虚设。虽然 ISO C 这里的 API 因为足够弱而现实被没有被广泛依赖，考虑到国际化问题的程序一般已经自行解决，但这不能保证大多数程序都已经正确地解决了这个问题，更避免不了依赖第三方库的国际化 API （如 ICU ）的复杂性和兼容碎片化问题。
* 宽字符指向缺乏可用性。宽字符指向是文件打开时决定是否使用宽字符类型 `wchar_t` 表示数据。打开流后，指向不能切换。与其说是特性，不如视为实现的限制。因为和特定编码耦合的问题（通常使用宽字符要求 UCS-2 或 UCS-4 兼容的编码；更根本地，因为字节度量的大小都无法保证一致，`wchar_t` 在二进制表示上不可移植）、一些实现支持的历史遗留的复杂问题（如某些情况下标准输出在 Windows 上未被使用预期的编码正确地实现）和一些未来扩展问题（如 `char16_t` 和 `char32_t` 的支持和互操作），宽字符 API 已经损失可用性。通常使用非标准库提供的国际化或 Unicode API 实现更特定的功能而完全避免这些问题。不过，这不能避免标准库的冗余，和已经依赖这些 API 的程序的微妙的不可移植性。
* 区域(locale) 原则上是不可移植的（除了默认的 `C` 区域——相当于不使用这项特性）。变通这些问题的方法类似，不使用 ISO C 的相关特性。但因为区域涉及编码在内的各项基本特性，配置组合过多，并且实际上 ISO C 在语言层次上就明确 locale-specific behavior 可能导致不可移植但被忽略，这里的实际问题更严重。

　　虽然和文件抽象的缺陷没有直接关联，值得一提的是，**根本地，这里的区域可移植性的问题可以看作语言设计的 API 混入了 UI 配置的失败范例**。

　　除去以上问题，以及和流本应没有耦合的格式输入/输出 API 的设计缺陷，ISO C 流相对底层实现真正提供的功能主要是流缓冲(stream buffering) 。但是，流的缓冲根本是和文件无关的概念。除了整体设置使用缓冲的选项，ISO C 没暴露缓冲的接口，所谓内存流(memory stream) 的概念也无法基于这个框架实现。这使 ISO C 的标准输入/输出流的可用性进一步下降。

　　类似地，ISO C++ 也存在 ISO C 流类似（但不完全相同）的问题。特别地，ISO C++ 使用更复杂的和 ISO 并行的同样无法保证可移植性但更复杂的区域 API ，即便事实上很少有程序直接依赖，用户也要付出二进制存储和运行时开销上的代价。ISO C++ 的流并没有 ISO C 这样强地依赖文件的抽象而允许独立实现和文件无关的流（但没有 ISO C 这样的行缓冲(line buffering) 的概念，需要用户自行实现），但其中的抽象复杂性仍使可用性充满疑问。只是 ISO C++ 标准库往往不随主流系统实现提供特定版本进行支持，所以这里的不必要的 API 依赖污染是伴随应用程序而非系统部署的，对非开发者的造成的问题可能会小一些。

　　即便常常被分解为“字符”类型（“字符”类型的概念混乱问题也是拜 UNIX 历史包袱所赐）的数据，正确的[流](https://zh.wikipedia.org/zh-cn/%E5%AD%97%E4%B8%B2%E6%B5%81)的抽象仅仅就是指允许非决定性访问的序列，实质上根本不依赖文件或者文本文件，和区域这样的用户配置更加全然无关。合理的流 API 的设计应摒除上述缺陷中依赖无用实现的细节。最有效的流的使用是体现和流以外其它常见抽象数据结构的差异，典型地如构造时不指定数据有限来源的情形，一个例子如 [SRFI-45](https://srfi.schemers.org/srfi-45/srfi-45.html) 。除非实现复杂的迭代器(iterator) ，这种情形下，语言通常需要能有效支持模拟不同的表达式的求值策略，在抽象能力有限的 ALGOL 语言上难以表达而不甚流行也是情理之中了。

